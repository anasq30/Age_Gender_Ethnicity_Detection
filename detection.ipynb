{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Detecting Age,Ethnicity & Gender using UTKFace detection dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in /opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.8/site-packages (4.5.5.64)\r\n",
      "Requirement already satisfied: numpy>=1.14.5 in /opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.8/site-packages (from opencv-python) (1.22.4)\r\n"
     ]
    }
   ],
   "source": [
    "!pip3 install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in /opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.8/site-packages (3.5.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.8/site-packages (from matplotlib) (21.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.8/site-packages (from matplotlib) (1.22.4)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.8/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.8/site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.8/site-packages (from matplotlib) (4.33.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.8/site-packages (from matplotlib) (1.4.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.8/site-packages (from matplotlib) (9.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.8/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.8/site-packages (from python-dateutil>=2.7->matplotlib) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.8/site-packages (1.1.1)\n",
      "Requirement already satisfied: joblib>=1.0.0 in /opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.8/site-packages (from scikit-learn) (1.1.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.8/site-packages (from scikit-learn) (1.22.4)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.8/site-packages (from scikit-learn) (3.1.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.8/site-packages (from scikit-learn) (1.8.1)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import tarfile as tr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.framework.ops import disable_eager_execution\n",
    "disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = tr.open('./UTKFace.tar')\n",
    "f.extractall('./images')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './images/UTKFace/'\n",
    "for file in os.listdir(path):\n",
    "  source = path + file\n",
    "  x = file.split('.')\n",
    "  rename = x[0]+'.'+x[1]\n",
    "  dest = path + rename\n",
    "  os.rename(source,dest)\n",
    "\n",
    "#check = os.listdir(path)\n",
    "#print(check)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bug_image1 = path + '61_1_20170109142408075.jpg'\n",
    "bug_image2 = path + '39_1_20170116174525125.jpg'\n",
    "bug_image3 = path + '61_1_20170109150557335.jpg'\n",
    "os.remove(bug_image1)\n",
    "os.remove(bug_image2)\n",
    "os.remove(bug_image3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = []\n",
    "labels = []\n",
    "path = './images/UTKFace/'\n",
    "for i in os.listdir(path):\n",
    "  sp = i.split('_')\n",
    "  ages = int(sp[0])\n",
    "  gender = int(sp[1])\n",
    "  ethnicity = int(sp[2])\n",
    "  labels.append([[ages],[gender],[ethnicity]])\n",
    "\n",
    "\n",
    "  img = cv2.imread(os.path.join(path,i))\n",
    "  img = cv2.resize(img,(128,128))\n",
    "  image.append(img)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[71], [1], [0]]\n"
     ]
    }
   ],
   "source": [
    "print(labels[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_labels = labels[0:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[26]\n",
      "  [ 0]\n",
      "  [ 1]]\n",
      "\n",
      " [[16]\n",
      "  [ 1]\n",
      "  [ 3]]]\n"
     ]
    }
   ],
   "source": [
    "Y = np.array(new_labels)\n",
    "print(Y[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_image = image[0:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(new_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 128, 3)\n"
     ]
    }
   ],
   "source": [
    "print(X[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 128, 128, 3)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 3, 1)\n"
     ]
    }
   ],
   "source": [
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "male :0 ; female:1,\n",
    "white:0 ; black:1 ; asian:2 ; indian:3 ; other:4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# counting number of males and females\n",
    "value,count = np.unique(Y[:,1],return_counts=True)\n",
    "plt.bar(['Male','Female'],count)\n",
    "plt.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4] [4293 1890 1415 1665  737]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "val,cnt = np.unique(Y[:,2],return_counts=True)\n",
    "print(val,cnt)\n",
    "plt.bar(['White','Black','Asian','Indian','Other'],cnt)\n",
    "plt.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,Y,test_size=0.2,random_state=41)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 128, 128, 3)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 128, 128, 3)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_5_input (InputLayer)  [(None, 128, 128, 3)]    0         \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 32, 32, 96)        34944     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 15, 15, 96)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " zero_padding2d_4 (ZeroPaddi  (None, 19, 19, 96)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 15, 15, 256)       614656    \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 7, 7, 256)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " zero_padding2d_5 (ZeroPaddi  (None, 9, 9, 256)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 7, 7, 384)         885120    \n",
      "                                                                 \n",
      " zero_padding2d_6 (ZeroPaddi  (None, 9, 9, 384)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 7, 7, 384)         1327488   \n",
      "                                                                 \n",
      " zero_padding2d_7 (ZeroPaddi  (None, 9, 9, 384)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 7, 7, 256)         884992    \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 3, 3, 256)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 3, 3, 256)         0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 2304)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 4096)              9441280   \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 4096)              16781312  \n",
      "                                                                 \n",
      " age (Dense)                 (None, 1)                 4097      \n",
      "                                                                 \n",
      " gender (Dense)              (None, 1)                 2         \n",
      "                                                                 \n",
      " ethnicity (Dense)           (None, 1)                 2         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 29,973,893\n",
      "Trainable params: 29,973,893\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(layers.Conv2D(96,(11,11),strides=(4,4),padding='same',activation='relu',input_shape=(128,128,3)))\n",
    "model.add(layers.MaxPool2D((3,3),strides=(2,2)))\n",
    "model.add(layers.ZeroPadding2D(padding=(2,2)))\n",
    "model.add(layers.Conv2D(256,(5,5),strides=(1,1),padding='valid',activation='relu'))\n",
    "model.add(layers.MaxPool2D((3,3),strides=(2,2)))\n",
    "model.add(layers.ZeroPadding2D(padding=(1,1)))\n",
    "model.add(layers.Conv2D(384,(3,3),strides=(1,1),padding='valid',activation='relu'))\n",
    "model.add(layers.ZeroPadding2D(padding=(1,1)))\n",
    "model.add(layers.Conv2D(384,(3,3),strides=(1,1),padding='valid',activation='relu'))\n",
    "model.add(layers.ZeroPadding2D(padding=(1,1)))\n",
    "model.add(layers.Conv2D(256,(3,3),strides=(1,1),padding='valid',activation='relu'))\n",
    "model.add(layers.MaxPool2D((3,3),strides=(2,2)))\n",
    "model.add(layers.Dropout(rate=0.5))\n",
    "\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(4096,activation='relu'))\n",
    "model.add(layers.Dropout(rate=0.5))\n",
    "model.add(layers.Dense(4096,activation='relu'))\n",
    "\n",
    "model.add(layers.Dense(1,activation='relu',name='age'))\n",
    "model.add(layers.Dense(1,activation='sigmoid',name='gender'))\n",
    "model.add(layers.Dense(1,activation='softmax',name='ethnicity'))\n",
    "\n",
    "model2 = keras.Model(inputs = model.inputs,outputs=[model.get_layer(name='age').output, model.get_layer(name='gender').output,model.get_layer(name='ethnicity').output])\n",
    "\n",
    "model2.compile(optimizer='adam',loss=['mse','binary_crossentropy','sparse_categorical_crossentropy'],metrics=['accuracy'])\n",
    "\n",
    "model2.summary()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0]\n",
      " [0]\n",
      " [0]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [0]]\n"
     ]
    }
   ],
   "source": [
    "y_train_final = [y_train[:,0],y_train[:,1],y_train[:,2]]\n",
    "print(y_train_final[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[55]\n",
      " [ 2]\n",
      " [31]\n",
      " ...\n",
      " [45]\n",
      " [54]\n",
      " [38]]\n"
     ]
    }
   ],
   "source": [
    "y_test_final = [y_test[:,0],y_test[:,1],y_test[:,2]]\n",
    "print(y_test_final[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8000 samples, validate on 2000 samples\n",
      "Metal device set to: Apple M1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-22 16:17:44.093896: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-06-22 16:17:44.095013: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2022-06-22 16:17:44.122971: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:354] MLIR V1 optimization pass is not enabled\n",
      "2022-06-22 16:17:44.142363: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2022-06-22 16:17:44.149143: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-06-22 16:17:44.216279: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-22 16:17:44.848422: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-06-22 16:17:44.875093: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-06-22 16:17:44.898758: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-06-22 16:17:44.921624: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-06-22 16:17:44.944852: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-06-22 16:17:44.967254: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-06-22 16:17:45.013009: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - ETA: 0s - loss: 509.8120 - age_loss: 488.6196 - gender_loss: 21.1924 - ethnicity_loss: 0.0000e+00 - age_accuracy: 0.0466 - gender_accuracy: 0.4765 - ethnicity_accuracy: 0.1880"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/mlp/lib/python3.8/site-packages/keras/engine/training_v1.py:2045: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n",
      "2022-06-22 16:18:20.483570: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 39s 5ms/sample - loss: 509.8120 - age_loss: 488.6196 - gender_loss: 21.1924 - ethnicity_loss: 0.0000e+00 - age_accuracy: 0.0466 - gender_accuracy: 0.4765 - ethnicity_accuracy: 0.1880 - val_loss: 440.5252 - val_age_loss: 423.3851 - val_gender_loss: 19.4984 - val_ethnicity_loss: 0.0000e+00 - val_age_accuracy: 0.0540 - val_gender_accuracy: 0.4650 - val_ethnicity_accuracy: 0.1930\n",
      "Epoch 2/20\n",
      "8000/8000 [==============================] - 38s 5ms/sample - loss: 427.8351 - age_loss: 409.5243 - gender_loss: 18.3108 - ethnicity_loss: 0.0000e+00 - age_accuracy: 0.0473 - gender_accuracy: 0.4764 - ethnicity_accuracy: 0.1880 - val_loss: 442.9974 - val_age_loss: 427.1253 - val_gender_loss: 14.7643 - val_ethnicity_loss: 0.0000e+00 - val_age_accuracy: 0.0540 - val_gender_accuracy: 0.4650 - val_ethnicity_accuracy: 0.1930\n",
      "Epoch 3/20\n",
      "8000/8000 [==============================] - 39s 5ms/sample - loss: 417.6652 - age_loss: 403.7153 - gender_loss: 13.9499 - ethnicity_loss: 0.0000e+00 - age_accuracy: 0.0473 - gender_accuracy: 0.4764 - ethnicity_accuracy: 0.1880 - val_loss: 438.9605 - val_age_loss: 428.9828 - val_gender_loss: 10.6790 - val_ethnicity_loss: 0.0000e+00 - val_age_accuracy: 0.0540 - val_gender_accuracy: 0.4650 - val_ethnicity_accuracy: 0.1930\n",
      "Epoch 4/20\n",
      "8000/8000 [==============================] - 39s 5ms/sample - loss: 415.0053 - age_loss: 405.4350 - gender_loss: 9.5703 - ethnicity_loss: 0.0000e+00 - age_accuracy: 0.0473 - gender_accuracy: 0.4764 - ethnicity_accuracy: 0.1880 - val_loss: 440.3973 - val_age_loss: 434.7014 - val_gender_loss: 6.5081 - val_ethnicity_loss: 0.0000e+00 - val_age_accuracy: 0.0540 - val_gender_accuracy: 0.4650 - val_ethnicity_accuracy: 0.1930\n",
      "Epoch 5/20\n",
      "8000/8000 [==============================] - 39s 5ms/sample - loss: 409.8564 - age_loss: 404.6933 - gender_loss: 5.1633 - ethnicity_loss: 0.0000e+00 - age_accuracy: 0.0473 - gender_accuracy: 0.4764 - ethnicity_accuracy: 0.1880 - val_loss: 441.1793 - val_age_loss: 439.0642 - val_gender_loss: 2.5342 - val_ethnicity_loss: 0.0000e+00 - val_age_accuracy: 0.0540 - val_gender_accuracy: 0.4650 - val_ethnicity_accuracy: 0.1930\n",
      "Epoch 6/20\n",
      "8000/8000 [==============================] - 39s 5ms/sample - loss: 406.6512 - age_loss: 405.2192 - gender_loss: 1.4322 - ethnicity_loss: 0.0000e+00 - age_accuracy: 0.0473 - gender_accuracy: 0.4759 - ethnicity_accuracy: 0.1880 - val_loss: 411.5797 - val_age_loss: 408.7562 - val_gender_loss: 0.7603 - val_ethnicity_loss: 0.0000e+00 - val_age_accuracy: 0.0540 - val_gender_accuracy: 0.4670 - val_ethnicity_accuracy: 0.1930\n",
      "Epoch 7/20\n",
      "8000/8000 [==============================] - 38s 5ms/sample - loss: 401.5178 - age_loss: 400.7643 - gender_loss: 0.7536 - ethnicity_loss: 0.0000e+00 - age_accuracy: 0.0473 - gender_accuracy: 0.4759 - ethnicity_accuracy: 0.1880 - val_loss: 420.7522 - val_age_loss: 418.2500 - val_gender_loss: 0.7281 - val_ethnicity_loss: 0.0000e+00 - val_age_accuracy: 0.0540 - val_gender_accuracy: 0.4650 - val_ethnicity_accuracy: 0.1930\n",
      "Epoch 8/20\n",
      "8000/8000 [==============================] - 40s 5ms/sample - loss: 400.1958 - age_loss: 399.4352 - gender_loss: 0.7607 - ethnicity_loss: 0.0000e+00 - age_accuracy: 0.0473 - gender_accuracy: 0.4763 - ethnicity_accuracy: 0.1880 - val_loss: 409.1712 - val_age_loss: 408.3671 - val_gender_loss: 0.7913 - val_ethnicity_loss: 0.0000e+00 - val_age_accuracy: 0.0540 - val_gender_accuracy: 0.4650 - val_ethnicity_accuracy: 0.1930\n",
      "Epoch 9/20\n",
      "8000/8000 [==============================] - 44s 6ms/sample - loss: 399.4553 - age_loss: 398.6743 - gender_loss: 0.7808 - ethnicity_loss: 0.0000e+00 - age_accuracy: 0.0473 - gender_accuracy: 0.4758 - ethnicity_accuracy: 0.1880 - val_loss: 413.8056 - val_age_loss: 411.3755 - val_gender_loss: 0.7713 - val_ethnicity_loss: 0.0000e+00 - val_age_accuracy: 0.0540 - val_gender_accuracy: 0.4650 - val_ethnicity_accuracy: 0.1930\n",
      "Epoch 10/20\n",
      "8000/8000 [==============================] - 40s 5ms/sample - loss: 398.9604 - age_loss: 398.1609 - gender_loss: 0.7996 - ethnicity_loss: 0.0000e+00 - age_accuracy: 0.0473 - gender_accuracy: 0.4753 - ethnicity_accuracy: 0.1880 - val_loss: 448.8341 - val_age_loss: 450.0443 - val_gender_loss: 0.7345 - val_ethnicity_loss: 0.0000e+00 - val_age_accuracy: 0.0540 - val_gender_accuracy: 0.4650 - val_ethnicity_accuracy: 0.1930\n",
      "Epoch 11/20\n",
      "8000/8000 [==============================] - 38s 5ms/sample - loss: 400.4429 - age_loss: 399.6290 - gender_loss: 0.8138 - ethnicity_loss: 0.0000e+00 - age_accuracy: 0.0473 - gender_accuracy: 0.4766 - ethnicity_accuracy: 0.1880 - val_loss: 459.6266 - val_age_loss: 459.1938 - val_gender_loss: 0.7410 - val_ethnicity_loss: 0.0000e+00 - val_age_accuracy: 0.0535 - val_gender_accuracy: 0.4650 - val_ethnicity_accuracy: 0.1930\n",
      "Epoch 12/20\n",
      "8000/8000 [==============================] - 43s 5ms/sample - loss: 400.0766 - age_loss: 399.2372 - gender_loss: 0.8395 - ethnicity_loss: 0.0000e+00 - age_accuracy: 0.0473 - gender_accuracy: 0.4761 - ethnicity_accuracy: 0.1880 - val_loss: 419.1599 - val_age_loss: 416.9420 - val_gender_loss: 0.8281 - val_ethnicity_loss: 0.0000e+00 - val_age_accuracy: 0.0540 - val_gender_accuracy: 0.4650 - val_ethnicity_accuracy: 0.1930\n",
      "Epoch 13/20\n",
      "8000/8000 [==============================] - 38s 5ms/sample - loss: 399.7952 - age_loss: 398.9312 - gender_loss: 0.8640 - ethnicity_loss: 0.0000e+00 - age_accuracy: 0.0473 - gender_accuracy: 0.4760 - ethnicity_accuracy: 0.1880 - val_loss: 410.8057 - val_age_loss: 410.4416 - val_gender_loss: 0.8572 - val_ethnicity_loss: 0.0000e+00 - val_age_accuracy: 0.0540 - val_gender_accuracy: 0.4655 - val_ethnicity_accuracy: 0.1930\n",
      "Epoch 14/20\n",
      "8000/8000 [==============================] - 37s 5ms/sample - loss: 399.8788 - age_loss: 398.9948 - gender_loss: 0.8840 - ethnicity_loss: 0.0000e+00 - age_accuracy: 0.0473 - gender_accuracy: 0.4758 - ethnicity_accuracy: 0.1880 - val_loss: 411.7028 - val_age_loss: 411.1142 - val_gender_loss: 0.8683 - val_ethnicity_loss: 0.0000e+00 - val_age_accuracy: 0.0540 - val_gender_accuracy: 0.4655 - val_ethnicity_accuracy: 0.1930\n",
      "Epoch 15/20\n",
      "8000/8000 [==============================] - 39s 5ms/sample - loss: 400.9356 - age_loss: 400.0295 - gender_loss: 0.9061 - ethnicity_loss: 0.0000e+00 - age_accuracy: 0.0473 - gender_accuracy: 0.4755 - ethnicity_accuracy: 0.1880 - val_loss: 412.9976 - val_age_loss: 412.8497 - val_gender_loss: 0.8833 - val_ethnicity_loss: 0.0000e+00 - val_age_accuracy: 0.0540 - val_gender_accuracy: 0.4650 - val_ethnicity_accuracy: 0.1930\n",
      "Epoch 16/20\n",
      "8000/8000 [==============================] - 39s 5ms/sample - loss: 397.6297 - age_loss: 396.7013 - gender_loss: 0.9283 - ethnicity_loss: 0.0000e+00 - age_accuracy: 0.0473 - gender_accuracy: 0.4764 - ethnicity_accuracy: 0.1880 - val_loss: 421.0760 - val_age_loss: 420.5100 - val_gender_loss: 0.8579 - val_ethnicity_loss: 0.0000e+00 - val_age_accuracy: 0.0540 - val_gender_accuracy: 0.4650 - val_ethnicity_accuracy: 0.1930\n",
      "Epoch 17/20\n",
      "8000/8000 [==============================] - 40s 5ms/sample - loss: 413.7080 - age_loss: 412.7632 - gender_loss: 0.9448 - ethnicity_loss: 0.0000e+00 - age_accuracy: 0.0473 - gender_accuracy: 0.4761 - ethnicity_accuracy: 0.1880 - val_loss: 438.5734 - val_age_loss: 439.7369 - val_gender_loss: 0.8896 - val_ethnicity_loss: 0.0000e+00 - val_age_accuracy: 0.0540 - val_gender_accuracy: 0.4650 - val_ethnicity_accuracy: 0.1930\n",
      "Epoch 18/20\n",
      "8000/8000 [==============================] - 38s 5ms/sample - loss: 399.4696 - age_loss: 398.4970 - gender_loss: 0.9725 - ethnicity_loss: 0.0000e+00 - age_accuracy: 0.0473 - gender_accuracy: 0.4766 - ethnicity_accuracy: 0.1880 - val_loss: 442.1738 - val_age_loss: 439.4337 - val_gender_loss: 0.8640 - val_ethnicity_loss: 0.0000e+00 - val_age_accuracy: 0.0540 - val_gender_accuracy: 0.4650 - val_ethnicity_accuracy: 0.1930\n",
      "Epoch 19/20\n",
      "8000/8000 [==============================] - 39s 5ms/sample - loss: 399.7987 - age_loss: 398.8086 - gender_loss: 0.9902 - ethnicity_loss: 0.0000e+00 - age_accuracy: 0.0473 - gender_accuracy: 0.4764 - ethnicity_accuracy: 0.1880 - val_loss: 423.4551 - val_age_loss: 422.8562 - val_gender_loss: 0.9586 - val_ethnicity_loss: 0.0000e+00 - val_age_accuracy: 0.0540 - val_gender_accuracy: 0.4650 - val_ethnicity_accuracy: 0.1930\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20\n",
      "8000/8000 [==============================] - 38s 5ms/sample - loss: 397.5109 - age_loss: 396.4966 - gender_loss: 1.0143 - ethnicity_loss: 0.0000e+00 - age_accuracy: 0.0473 - gender_accuracy: 0.4764 - ethnicity_accuracy: 0.1880 - val_loss: 425.3912 - val_age_loss: 423.3596 - val_gender_loss: 0.9664 - val_ethnicity_loss: 0.0000e+00 - val_age_accuracy: 0.0540 - val_gender_accuracy: 0.4650 - val_ethnicity_accuracy: 0.1930\n"
     ]
    }
   ],
   "source": [
    "train = model2.fit(X_train,y_train_final,batch_size=32,epochs=20,validation_data=(X_test,y_test_final),shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Age: 24\n",
      "Actual Gender: Female\n",
      "Actual Ethnicity: Black\n",
      "Predicted Age: 30\n",
      "Predicted Gender: Female\n",
      "predicted Ethnicity: Black\n"
     ]
    }
   ],
   "source": [
    "img_files = os.listdir(path)\n",
    "i = 440\n",
    "\n",
    "gender = ['Male', 'Female']\n",
    "ethnicity = ['White','Black','Asian','Indian','other']\n",
    "print(\"Actual Age: \" + str(int(img_files[i].split('_')[0])))\n",
    "print(\"Actual Gender: \" + gender[int(img_files[i].split('_')[1])])\n",
    "print(\"Actual Ethnicity: \"+ethnicity[int(img_files[i].split('_')[2])])\n",
    "\n",
    "test = X[i]\n",
    "prediction = model2.predict(np.array([test]))\n",
    "print(\"Predicted Age: \" + str(int(np.round(prediction[0][0]))))\n",
    "print(\"Predicted Gender: \" + gender[int(np.round(prediction[1][0]))])\n",
    "print(\"predicted Ethnicity: \" + ethnicity[int(np.round(prediction[2][0]))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
